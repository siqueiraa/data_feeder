# Data Feeder Configuration File
# 
# FEATURE FLAGS AND CONFIGURATION ALIGNMENT (Story 3.5)
# =====================================================
# This configuration file demonstrates all valid feature flag combinations.
# Features are enabled in Cargo.toml and configured here in config.toml.
#
# Available Features:
# - postgres: PostgreSQL storage backend  
# - kafka: Kafka message publishing
# - volume_profile: Volume profile technical analysis
# - volume_profile_reprocessing: Historical volume profile reprocessing (requires volume_profile)
#
# Feature Dependency Matrix:
# ┌──────────────────────────────┬─────────────────────────────────────────────────────┐
# │ Feature                      │ Dependencies                                        │
# ├──────────────────────────────┼─────────────────────────────────────────────────────┤
# │ postgres                     │ None                                                │
# │ kafka                        │ None                                                │
# │ volume_profile               │ None                                                │
# │ volume_profile_reprocessing  │ volume_profile (required)                          │
# └──────────────────────────────┴─────────────────────────────────────────────────────┘
#
# Valid Feature Combinations:
# - [] (no features): Minimal LMDB-only storage
# - [postgres]: PostgreSQL storage only
# - [kafka]: Kafka publishing only
# - [volume_profile]: Volume profile analysis only
# - [postgres, kafka]: Dual storage with publishing
# - [postgres, volume_profile]: PostgreSQL with volume analysis
# - [kafka, volume_profile]: Kafka publishing with volume analysis
# - [postgres, kafka, volume_profile]: Full feature set
# - [volume_profile, volume_profile_reprocessing]: Volume profile with reprocessing
# - [postgres, kafka, volume_profile, volume_profile_reprocessing]: Full feature set with reprocessing
#
# INVALID Combinations (will cause validation errors):
# - [volume_profile_reprocessing]: Missing required volume_profile dependency
#
# Configuration Sections:
# - Sections for disabled features will be ignored with warnings
# - Invalid values in enabled features will cause validation errors
# - Missing required configuration for enabled features will cause errors

[database]
# PostgreSQL connection settings (requires 'postgres' feature)
# NOTE: This section is ignored if the 'postgres' feature is not enabled in Cargo.toml
# To enable: Add 'postgres' to the features list in Cargo.toml
host = "localhost"          # Required: PostgreSQL server hostname
port = 5432                 # Required: PostgreSQL server port (must be > 0)
database = "crypto_data"    # Required: Database name (cannot be empty)
username = "postgres"       # Required: Database username (cannot be empty)
password = "your_password"  # Database password
max_connections = 10        # Connection pool size
connection_timeout_seconds = 30

# Storage settings
batch_size = 1000           # Number of records per batch
batch_timeout_seconds = 5   # Maximum time to wait before committing batch
enabled = false             # Set to true to enable PostgreSQL storage
                           # Validation: If enabled=true, host, database, username must not be empty

[application]
# Application settings
symbols = ["BTCUSDT"]
timeframes = [60]  # 1 minute in seconds
storage_path = "lmdb_data"
gap_detection_enabled = true
start_date = "2025-01-01T00:00:00Z"  # Optional start date for historical data
respect_config_start_date = false
monthly_threshold_months = 3
enable_technical_analysis = true

# HTTP server settings
health_server_port = 8080  # Port for health checks, metrics, and readiness probes

# WebSocket reconnection settings
reconnection_gap_threshold_minutes = 1
reconnection_gap_check_delay_seconds = 5

# Periodic gap detection settings (prevents data loss during stable connections)
periodic_gap_detection_enabled = true
periodic_gap_check_interval_minutes = 5  # How often to scan for gaps
periodic_gap_check_window_minutes = 30   # How far back to scan for gaps

[technical_analysis]
# Technical analysis configuration
min_history_days = 60
ema_periods = [21, 89]
timeframes = [60, 300, 900, 3600, 14400]  # 1m, 5m, 15m, 1h, 4h
volume_lookback_days = 60

[kafka]
# Kafka producer settings for technical analysis indicators (requires 'kafka' feature)
# NOTE: This section is ignored if the 'kafka' feature is not enabled in Cargo.toml
# To enable: Add 'kafka' to the features list in Cargo.toml
enabled = false                         # Set to true to enable Kafka publishing
bootstrap_servers = ["localhost:9092"] # Required: Kafka broker addresses (cannot be empty list)
topic_prefix = "ta_"                   # Required: Topic prefix (cannot be empty string)
client_id = "data_feeder_rust"         # Kafka client identifier
acks = "all"                           # Message durability setting
retries = 3
max_in_flight_requests_per_connection = 1
compression_type = "snappy"
batch_size = 16384
linger_ms = 10
request_timeout_ms = 30000
delivery_timeout_ms = 120000

# Validation Rules:
# - If enabled=true, bootstrap_servers must not be empty
# - If enabled=true, topic_prefix must not be empty

[volume_profile]
# Volume Profile settings - Asset-aware configuration (requires 'volume_profile' feature)
# NOTE: This section is ignored if the 'volume_profile' feature is not enabled in Cargo.toml
# To enable: Add 'volume_profile' to the features list in Cargo.toml
enabled = true
price_increment_mode = "Adaptive"    # "Fixed" or "Adaptive" - Adaptive recommended for multi-asset
target_price_levels = 500           # Target number of price levels per range (adaptive mode)
fixed_price_increment = 0.01        # Used when mode is "Fixed"
min_price_increment = 0.00000001    # Minimum increment for adaptive mode (altcoin precision)
max_price_increment = 1.0         # Maximum increment for adaptive mode (high-value assets)
volume_distribution_mode = "WeightedOHLC"          # "UniformOHLC", "ClosingPrice", "WeightedOHLC", "HighLowWeighted"
value_area_calculation_mode = "Traditional"       # "Traditional", "Greedy"
calculation_mode = "Volume"                      # "Volume" or "TPO" - Controls POC and value area calculation method
update_frequency = "EveryCandle"    # "EveryCandle" or "Batched"
batch_size = 1                      # Number of profiles to batch before storage
value_area_percentage = 70.0        # Percentage of volume to include in value area (industry standard)

# Volume Profile Calculation Methods:
# - "Volume": Weight by actual trading volume (default, most common)
#   POC = price level with highest volume, VA = 70% of total volume
# - "TPO": Weight by time periods/candle count (traditional Market Profile)
#   POC = price level with most time periods, VA = 70% of total time periods

# Asset-specific overrides (optional - for fine-tuning specific assets)
[volume_profile.asset_overrides]
# High-value assets with fixed increments for better performance
"BTCUSDT" = { price_increment_mode = "Fixed", fixed_price_increment = 10.0, calculation_mode = "Volume" }   # $10 increments for Bitcoin
"ETHUSDT" = { price_increment_mode = "Fixed", fixed_price_increment = 1.0, calculation_mode = "Volume" }    # $1 increments for Ethereum

# Mid-value assets
"SOLUSDT" = { price_increment_mode = "Fixed", fixed_price_increment = 0.1, calculation_mode = "Volume" }    # $0.10 increments for Solana
"ADAUSDT" = { price_increment_mode = "Fixed", fixed_price_increment = 0.001, calculation_mode = "Volume" }  # $0.001 increments for Cardano

# Micro-cap altcoins with ultra-precise adaptive ranges
"PEPEUSDT" = { price_increment_mode = "Adaptive", min_price_increment = 0.00000001, max_price_increment = 0.000001, calculation_mode = "TPO" }
"SHIBUSDT" = { price_increment_mode = "Adaptive", min_price_increment = 0.00000001, max_price_increment = 0.00001, calculation_mode = "TPO" }

# Volume Profile Reprocessing settings (requires 'volume_profile_reprocessing' feature)
# NOTE: Requires BOTH 'volume_profile' AND 'volume_profile_reprocessing' features
# To enable: Add both 'volume_profile' and 'volume_profile_reprocessing' to Cargo.toml features
[volume_profile.reprocessing]
enabled = false  # Set to true to enable reprocessing functionality
mode = "missing_days_only"  # "reprocess_whole_history", "missing_days_only", "today_only"
batch_size = 10  # Number of days to process in each batch

# Validation Rules:
# - target_price_levels: Warning if < 10 (may reduce analysis accuracy)
# - historical_days: Error if = 0 (must be > 0)
# - reprocessing: Only available if volume_profile_reprocessing feature enabled

[adaptive]
# Adaptive resource configuration system
enabled = true  # Enable adaptive configuration based on system resources

# Manual overrides for adaptive configuration
# (all parameters are optional - omit to use adaptive values)
[adaptive.overrides]
# Thread pool overrides
# worker_threads = 8       # Override worker thread count
# io_threads = 16          # Override I/O thread count
# cpu_threads = 4          # Override CPU-intensive thread count
# network_threads = 2      # Override network thread count

# Buffer size overrides (in MB for convenience)
# websocket_buffer_mb = 16    # WebSocket message buffer (MB)
# database_buffer_mb = 64     # Database batch buffer (MB)
# file_io_buffer_mb = 32      # File I/O buffer (MB)
# network_buffer_mb = 8       # Network buffer (MB)

# Processing batch size overrides
# database_batch_size = 2000  # Database batch size (number of records)
# api_batch_size = 100        # API request batch size
# file_chunk_size = 16384     # File processing chunk size
# memory_chunk_size = 8192    # Memory processing chunk size

# Memory management overrides
# max_memory_usage_percent = 75.0         # Maximum memory usage (0-100%)
# cleanup_threshold_percent = 65.0        # Memory cleanup threshold (0-100%)
# cache_size_mb = 512                     # Cache size limit (MB)
# enable_memory_intensive_features = true # Enable memory-intensive features

# Disable adaptive configuration entirely (use static defaults)
# disable_adaptive = false

# ================================================================
# EXAMPLE CONFIGURATIONS FOR DIFFERENT FEATURE COMBINATIONS
# ================================================================

# Example 1: Minimal Configuration (no features enabled)
# Cargo.toml: features = []
# - Only LMDB storage
# - No PostgreSQL, Kafka, or Volume Profile
# - [database], [kafka], [volume_profile] sections will be ignored with warnings

# Example 2: PostgreSQL Only
# Cargo.toml: features = ["postgres"]
# - Enable [database] section with enabled = true
# - [kafka], [volume_profile] sections ignored with warnings

# Example 3: Full Feature Set
# Cargo.toml: features = ["postgres", "kafka", "volume_profile", "volume_profile_reprocessing"]
# - All sections active and validated
# - Configuration migration warnings for potentially resource-intensive setup

# Example 4: Volume Profile with Reprocessing
# Cargo.toml: features = ["volume_profile", "volume_profile_reprocessing"] 
# - [volume_profile] section active with reprocessing enabled
# - [database], [kafka] sections ignored with warnings

# TROUBLESHOOTING QUICK REFERENCE
# ================================
# Common Configuration Errors:
#
# Error: "PostgreSQL is enabled but host is empty"
# Fix: Set database.host = "localhost" (or your PostgreSQL server address)
#
# Error: "Kafka is enabled but no bootstrap servers are configured" 
# Fix: Set kafka.bootstrap_servers = ["localhost:9092"] (or your Kafka brokers)
#
# Error: "Feature 'volume_profile_reprocessing' requires 'volume_profile'"
# Fix: Add "volume_profile" to Cargo.toml features list
#
# Error: "Volume profile historical_days cannot be 0"
# Fix: Set volume_profile.historical_days to a value > 0 (e.g., 30)
#
# Warning: "Volume profile target price levels (5) is low"
# Suggestion: Increase volume_profile.target_price_levels to at least 10-20